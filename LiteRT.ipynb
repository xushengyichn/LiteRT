{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qK5EhGGNMOJh"
      },
      "source": [
        "# LiteRT using Google AI Edge for on-device object detection\n",
        "This notebook is an implementation of converting the YOLO11 object detection model to LiteRT (.tflite) format using Google AI Edge and deploy it on Android for on-device inference.\n",
        "\n",
        "Developed by [Levi Lin](https://github.com/gy6543721)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UXou4eK436nb"
      },
      "source": [
        "#### Step 1: Install dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YNzOT6QeJo-1",
        "outputId": "d5b7414e-e65a-44d7-df7d-649824470bda"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ultralytics in /usr/local/lib/python3.11/dist-packages (8.3.83)\n",
            "Requirement already satisfied: numpy<=2.1.1,>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.26.4)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.11.0.86)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (11.1.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.13.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.5.1+cu124)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.20.1+cu124)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.13.2)\n",
            "Requirement already satisfied: ultralytics-thop>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.0.14)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2025.1.31)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
            "Requirement already satisfied: ai-edge-model-explorer in /usr/local/lib/python3.11/dist-packages (0.1.18)\n",
            "Requirement already satisfied: flask in /usr/local/lib/python3.11/dist-packages (from ai-edge-model-explorer) (3.1.0)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.11/dist-packages (from ai-edge-model-explorer) (7.34.0)\n",
            "Requirement already satisfied: ai-edge-model-explorer-adapter==0.1.5 in /usr/local/lib/python3.11/dist-packages (from ai-edge-model-explorer) (0.1.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from ai-edge-model-explorer) (24.2)\n",
            "Requirement already satisfied: portpicker in /usr/local/lib/python3.11/dist-packages (from ai-edge-model-explorer) (1.5.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from ai-edge-model-explorer) (2.32.3)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.11/dist-packages (from ai-edge-model-explorer) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from ai-edge-model-explorer) (4.12.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from ai-edge-model-explorer) (1.26.4)\n",
            "Requirement already satisfied: Werkzeug>=3.1 in /usr/local/lib/python3.11/dist-packages (from flask->ai-edge-model-explorer) (3.1.3)\n",
            "Requirement already satisfied: Jinja2>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from flask->ai-edge-model-explorer) (3.1.5)\n",
            "Requirement already satisfied: itsdangerous>=2.2 in /usr/local/lib/python3.11/dist-packages (from flask->ai-edge-model-explorer) (2.2.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from flask->ai-edge-model-explorer) (8.1.8)\n",
            "Requirement already satisfied: blinker>=1.9 in /usr/local/lib/python3.11/dist-packages (from flask->ai-edge-model-explorer) (1.9.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.11/dist-packages (from ipython->ai-edge-model-explorer) (75.1.0)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.11/dist-packages (from ipython->ai-edge-model-explorer) (0.19.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython->ai-edge-model-explorer) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython->ai-edge-model-explorer) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.11/dist-packages (from ipython->ai-edge-model-explorer) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython->ai-edge-model-explorer) (3.0.50)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython->ai-edge-model-explorer) (2.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython->ai-edge-model-explorer) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.11/dist-packages (from ipython->ai-edge-model-explorer) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython->ai-edge-model-explorer) (4.9.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from portpicker->ai-edge-model-explorer) (5.9.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->ai-edge-model-explorer) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->ai-edge-model-explorer) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->ai-edge-model-explorer) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->ai-edge-model-explorer) (2025.1.31)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython->ai-edge-model-explorer) (0.8.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from Jinja2>=3.1.2->flask->ai-edge-model-explorer) (3.0.2)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython->ai-edge-model-explorer) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->ai-edge-model-explorer) (0.2.13)\n",
            "Requirement already satisfied: ai-edge-litert in /usr/local/lib/python3.11/dist-packages (1.1.2)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from ai-edge-litert) (25.2.10)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from ai-edge-litert) (1.26.4)\n",
            "Requirement already satisfied: simple-onnx-processing-tools in /usr/local/lib/python3.11/dist-packages (1.1.32)\n",
            "Requirement already satisfied: snc4onnx>=1.0.12 in /usr/local/lib/python3.11/dist-packages (from simple-onnx-processing-tools) (1.0.13)\n",
            "Requirement already satisfied: sne4onnx>=1.0.11 in /usr/local/lib/python3.11/dist-packages (from simple-onnx-processing-tools) (1.0.13)\n",
            "Requirement already satisfied: snd4onnx>=1.1.6 in /usr/local/lib/python3.11/dist-packages (from simple-onnx-processing-tools) (1.1.6)\n",
            "Requirement already satisfied: scs4onnx>=1.0.18 in /usr/local/lib/python3.11/dist-packages (from simple-onnx-processing-tools) (1.0.18)\n",
            "Requirement already satisfied: sog4onnx>=1.0.16 in /usr/local/lib/python3.11/dist-packages (from simple-onnx-processing-tools) (1.0.17)\n",
            "Requirement already satisfied: sam4onnx>=1.0.14 in /usr/local/lib/python3.11/dist-packages (from simple-onnx-processing-tools) (1.0.16)\n",
            "Requirement already satisfied: soc4onnx>=1.0.2 in /usr/local/lib/python3.11/dist-packages (from simple-onnx-processing-tools) (1.0.2)\n",
            "Requirement already satisfied: scc4onnx>=1.0.5 in /usr/local/lib/python3.11/dist-packages (from simple-onnx-processing-tools) (1.0.6)\n",
            "Requirement already satisfied: sna4onnx>=1.0.6 in /usr/local/lib/python3.11/dist-packages (from simple-onnx-processing-tools) (1.0.6)\n",
            "Requirement already satisfied: sbi4onnx>=1.0.5 in /usr/local/lib/python3.11/dist-packages (from simple-onnx-processing-tools) (1.0.7)\n",
            "Requirement already satisfied: sor4onnx>=1.0.5 in /usr/local/lib/python3.11/dist-packages (from simple-onnx-processing-tools) (1.0.7)\n",
            "Requirement already satisfied: sit4onnx>=1.0.7 in /usr/local/lib/python3.11/dist-packages (from simple-onnx-processing-tools) (1.0.8)\n",
            "Requirement already satisfied: onnx2json>=2.0.4 in /usr/local/lib/python3.11/dist-packages (from simple-onnx-processing-tools) (2.0.4)\n",
            "Requirement already satisfied: json2onnx>=2.0.3 in /usr/local/lib/python3.11/dist-packages (from simple-onnx-processing-tools) (2.0.3)\n",
            "Requirement already satisfied: sed4onnx>=1.0.5 in /usr/local/lib/python3.11/dist-packages (from simple-onnx-processing-tools) (1.0.5)\n",
            "Requirement already satisfied: soa4onnx>=1.0.4 in /usr/local/lib/python3.11/dist-packages (from simple-onnx-processing-tools) (1.0.4)\n",
            "Requirement already satisfied: sod4onnx>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from simple-onnx-processing-tools) (1.0.0)\n",
            "Requirement already satisfied: ssi4onnx>=1.0.2 in /usr/local/lib/python3.11/dist-packages (from simple-onnx-processing-tools) (1.0.4)\n",
            "Requirement already satisfied: ssc4onnx>=1.0.5 in /usr/local/lib/python3.11/dist-packages (from simple-onnx-processing-tools) (1.0.8)\n",
            "Requirement already satisfied: sio4onnx>=1.0.2 in /usr/local/lib/python3.11/dist-packages (from simple-onnx-processing-tools) (1.0.2)\n",
            "Requirement already satisfied: svs4onnx>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from simple-onnx-processing-tools) (1.0.0)\n",
            "Requirement already satisfied: onnx2tf>=1.20.1 in /usr/local/lib/python3.11/dist-packages (from simple-onnx-processing-tools) (1.26.3)\n",
            "Requirement already satisfied: sng4onnx>=1.0.2 in /usr/local/lib/python3.11/dist-packages (from simple-onnx-processing-tools) (1.0.4)\n",
            "Requirement already satisfied: sde4onnx>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from simple-onnx-processing-tools) (1.0.0)\n",
            "Requirement already satisfied: spo4onnx>=1.0.4 in /usr/local/lib/python3.11/dist-packages (from simple-onnx-processing-tools) (1.0.5)\n",
            "Requirement already satisfied: onnx_graphsurgeon in /usr/local/lib/python3.11/dist-packages (0.5.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from onnx_graphsurgeon) (1.26.4)\n",
            "Requirement already satisfied: onnx>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from onnx_graphsurgeon) (1.17.0)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from onnx>=1.14.0->onnx_graphsurgeon) (3.20.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install ultralytics\n",
        "!pip install ai-edge-model-explorer\n",
        "!pip install ai-edge-litert\n",
        "!pip install simple-onnx-processing-tools\n",
        "!pip install onnx_graphsurgeon\n",
        "!pip install onnxslim\n",
        "!pip install tflite_support\n",
        "!pip install onnxruntime\n",
        "!pip install protobuf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eEQRsPqv6GCc"
      },
      "source": [
        "#### Step 2: Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "SB12S2E7J0O8"
      },
      "outputs": [],
      "source": [
        "from ultralytics import YOLO\n",
        "from ai_edge_litert.interpreter import Interpreter\n",
        "from google.colab import files\n",
        "\n",
        "import model_explorer\n",
        "import yaml\n",
        "import json\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TgFnfd3K6-aS"
      },
      "source": [
        "#### Step 3: Convert YOLO11 model to LiteRT (TF Lite)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 744
        },
        "id": "b03zjtZkzZjz",
        "outputId": "93430377-46ad-496c-8d5c-e5900184a97f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.83 üöÄ Python-3.11.11 torch-2.5.1+cu124 CPU (AMD EPYC 7B12)\n",
            "YOLO11n summary (fused): 100 layers, 2,616,248 parameters, 0 gradients, 6.5 GFLOPs\n",
            "\n",
            "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'yolo11n.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 84, 8400) (5.4 MB)\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirements ['onnx_graphsurgeon>=0.3.26', 'onnxslim>=0.1.31', 'tflite_support', 'onnxruntime', 'protobuf>=5'] not found, attempting AutoUpdate...\n",
            "Retry 1/2 failed: Command 'pip install --no-cache-dir \"onnx_graphsurgeon>=0.3.26\" \"onnxslim>=0.1.31\" \"tflite_support\" \"onnxruntime\" \"protobuf>=5\" --extra-index-url https://pypi.ngc.nvidia.com' returned non-zero exit status 1.\n",
            "Retry 2/2 failed: Command 'pip install --no-cache-dir \"onnx_graphsurgeon>=0.3.26\" \"onnxslim>=0.1.31\" \"tflite_support\" \"onnxruntime\" \"protobuf>=5\" --extra-index-url https://pypi.ngc.nvidia.com' returned non-zero exit status 1.\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m ‚ùå Command 'pip install --no-cache-dir \"onnx_graphsurgeon>=0.3.26\" \"onnxslim>=0.1.31\" \"tflite_support\" \"onnxruntime\" \"protobuf>=5\" --extra-index-url https://pypi.ngc.nvidia.com' returned non-zero exit status 1.\n",
            "\n",
            "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m starting export with tensorflow 2.18.0...\n",
            "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m export failure ‚ùå 12.0s: No module named 'onnx_graphsurgeon'\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'onnx_graphsurgeon'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-84736736b7d2>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Export the model to LiteRT (TF Lite) format.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"tflite\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/engine/model.py\u001b[0m in \u001b[0;36mexport\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    740\u001b[0m         }  # method defaults\n\u001b[1;32m    741\u001b[0m         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcustom\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"mode\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"export\"\u001b[0m\u001b[0;34m}\u001b[0m  \u001b[0;31m# highest priority args on the right\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 742\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mExporter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_callbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    743\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    744\u001b[0m     def train(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/engine/exporter.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m    436\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_tf_format\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# TensorFlow formats\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint8\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0medgetpu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 438\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeras_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport_saved_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    439\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpb\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtfjs\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pb prerequisite to tfjs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport_pb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeras_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/engine/exporter.py\u001b[0m in \u001b[0;36mouter_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m             \u001b[0mLOGGER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{prefix} export failure ‚ùå {dt.t:.1f}s: {e}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mouter_func\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/engine/exporter.py\u001b[0m in \u001b[0;36mouter_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mProfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minner_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m             \u001b[0mLOGGER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{prefix} export success ‚úÖ {dt.t:.1f}s, saved as '{f}' ({file_size(f):.1f} MB)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/engine/exporter.py\u001b[0m in \u001b[0;36mexport_saved_model\u001b[0;34m(self, prefix)\u001b[0m\n\u001b[1;32m   1025\u001b[0m             \u001b[0mmsg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"https://github.com/ultralytics/ultralytics/issues/5161\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1026\u001b[0m         )\n\u001b[0;32m-> 1027\u001b[0;31m         \u001b[0;32mimport\u001b[0m \u001b[0monnx2tf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1029\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuffix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_saved_model\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/onnx2tf/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0monnx2tf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monnx2tf\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0m__version__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'1.26.3'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/onnx2tf/onnx2tf.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0monnx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0monnx_graphsurgeon\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mgs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0margparse\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mArgumentParser\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'onnx_graphsurgeon'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "# Load the YOLO11 model.\n",
        "model = YOLO(\"yolo11n.pt\")\n",
        "\n",
        "# Export the model to LiteRT (TF Lite) format.\n",
        "model.export(format=\"tflite\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_WII5g-lHXdu"
      },
      "source": [
        "Download a sample image or load your own image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ip6wk1nPHX6O"
      },
      "outputs": [],
      "source": [
        "# Download sample image and video.\n",
        "!wget https://raw.githubusercontent.com/gy6543721/LiteRT/main/assets/test_image.jpg\n",
        "!wget https://raw.githubusercontent.com/gy6543721/LiteRT/main/assets/test_image_2.jpg\n",
        "!wget https://raw.githubusercontent.com/gy6543721/LiteRT/main/assets/test_video.mp4\n",
        "\n",
        "image = Image.open('test_image_2.jpg')\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.imshow(image)\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DYOur8jdU1n8"
      },
      "outputs": [],
      "source": [
        "LITE_RT_EXPORT_PATH = \"yolo11n_saved_model/\" # @param {type : 'string'}\n",
        "LITE_RT_MODEL = \"yolo11n_float32.tflite\" # @param {type : 'string'}\n",
        "\n",
        "LITE_RT_MODEL_PATH = LITE_RT_EXPORT_PATH + LITE_RT_MODEL\n",
        "\n",
        "# Load the exported TF Lite model.\n",
        "litert_model = YOLO(LITE_RT_MODEL_PATH, task = 'detect')\n",
        "\n",
        "# Input image.\n",
        "image = 'test_image_2.jpg' # @param {type : 'string'}\n",
        "\n",
        "# Perform inference on the input image.\n",
        "result = litert_model(image)\n",
        "result[0].show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GxoxnVgMM2Wd"
      },
      "source": [
        "#### Step 4: Visualize the LiteRT model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aj3HbJB1NMZ9"
      },
      "outputs": [],
      "source": [
        "model_explorer.visualize(LITE_RT_MODEL_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rJm6c5kh-LtC"
      },
      "source": [
        "#### Step 5: Create labelmap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JRmCeCwWM2nI",
        "outputId": "a3ce1bc3-3a4d-49de-f21e-08d08f441a60"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Labelmap created.\n"
          ]
        }
      ],
      "source": [
        "metadata_file = \"metadata.yaml\" # @param {type : 'string'}\n",
        "json_file = \"labels.json\" # @param {type : 'string'}\n",
        "\n",
        "metadata_path = LITE_RT_EXPORT_PATH + metadata_file\n",
        "\n",
        "with open(metadata_path, \"r\") as file:\n",
        "    metadata = yaml.safe_load(file)\n",
        "\n",
        "names = metadata.get(\"names\", {})\n",
        "\n",
        "with open(json_file, 'w') as file:\n",
        "  json.dump(names, file, indent=2)\n",
        "\n",
        "print(\"Labelmap created.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4uGY6Z2b_ruS"
      },
      "source": [
        "#### Step 6: Inference the TF Lite model using LiteRT interpreter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I0RrQKBWAdl7"
      },
      "outputs": [],
      "source": [
        "# Load the TF Lite model.\n",
        "interpreter = Interpreter(model_path = LITE_RT_MODEL_PATH)\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "# Get input and output details.\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "\n",
        "input_size = input_details[0]['shape'][1]\n",
        "\n",
        "print(f\"Model input size: {input_size}\")\n",
        "print(f\"Output tensor shape: {output_details[0]['shape']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jhcdQCUPAjkK"
      },
      "source": [
        "#### Step 7: Define utility functions\n",
        "\n",
        "`load_labels`: Loads the `labels.json` file.\n",
        "\n",
        "`load_image`: Loads the input image.\n",
        "\n",
        "`detect`: Run the LiteRT model.\n",
        "\n",
        "`postprocess_output`: Normalize the bounding box coordinates.\n",
        "\n",
        "`generate_color_map`: Generates unique colors randomly for each label.\n",
        "\n",
        "`inference_image`: Inference detection on images.\n",
        "\n",
        "`inference_video`: Inference detection on videos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "code",
        "id": "vCvrq4uPA9QK"
      },
      "outputs": [],
      "source": [
        "# Load labels.\n",
        "def load_labels(label_file):\n",
        "  with open(label_file, 'r') as file:\n",
        "    return json.load(file)\n",
        "\n",
        "\n",
        "# Load and preprocess image.\n",
        "def load_image(image_path, input_size):\n",
        "  image = cv2.imread(image_path)\n",
        "  original_height, original_width = image.shape[:2]\n",
        "  image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "  image = cv2.resize(image, (input_size, input_size))\n",
        "  image = image / 255.0\n",
        "  return image, (original_height, original_width)\n",
        "\n",
        "\n",
        "# Run inference.\n",
        "def detect(input_data, is_video_frame=False):\n",
        "    input_size = input_details[0]['shape'][1]\n",
        "\n",
        "    if is_video_frame:\n",
        "        original_height, original_width = input_data.shape[:2]\n",
        "        image = cv2.cvtColor(input_data, cv2.COLOR_BGR2RGB)\n",
        "        image = cv2.resize(image, (input_size, input_size))\n",
        "        image = image / 255.0\n",
        "    else:\n",
        "        image, (original_height, original_width) = load_image(input_data, input_size)\n",
        "\n",
        "    interpreter.set_tensor(input_details[0]['index'], np.expand_dims(image, axis=0).astype(np.float32))\n",
        "    interpreter.invoke()\n",
        "\n",
        "    output_data = [interpreter.get_tensor(detail['index']) for detail in output_details]\n",
        "    return output_data, (original_height, original_width)\n",
        "\n",
        "\n",
        "\n",
        "# Postprocess the output.\n",
        "def postprocess_output(output_data, original_dims, labels, confidence_threshold):\n",
        "  output_tensor = output_data[0]\n",
        "  detections = []\n",
        "  original_height, original_width = original_dims\n",
        "\n",
        "  for i in range(output_tensor.shape[1]):\n",
        "    box = output_tensor[0, i, :4]\n",
        "    confidence = output_tensor[0, i, 4]\n",
        "    class_id = int(output_tensor[0, i, 5])\n",
        "\n",
        "    if confidence > confidence_threshold:\n",
        "      x_min = int(box[0] * original_width)\n",
        "      y_min = int(box[1] * original_height)\n",
        "      x_max = int(box[2] * original_width)\n",
        "      y_max = int(box[3] * original_height)\n",
        "\n",
        "      label_name = labels.get(str(class_id), \"Unknown\")\n",
        "\n",
        "      detections.append({\n",
        "          \"box\": [y_min, x_min, y_max, x_max],\n",
        "          \"score\": confidence,\n",
        "          \"class\": class_id,\n",
        "          \"label\": label_name\n",
        "      })\n",
        "\n",
        "  return detections\n",
        "\n",
        "\n",
        "# Generate color map for labels.\n",
        "def generate_color_map(labels):\n",
        "  color_map = {}\n",
        "  for label in labels.values():\n",
        "      color_map[label] = [random.randint(0, 255) for _ in range(3)]\n",
        "  return color_map\n",
        "\n",
        "\n",
        "# Inference on image.\n",
        "def inference_image(image_path, detections, color_map):\n",
        "  image = cv2.imread(image_path)\n",
        "  image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "  for detection in detections:\n",
        "    box = detection['box']\n",
        "    label = detection['label']\n",
        "    score = detection['score']\n",
        "    color = color_map[label]\n",
        "\n",
        "    y_min, x_min, y_max, x_max = box\n",
        "    cv2.rectangle(image, (x_min, y_min), (x_max, y_max), color, 3)\n",
        "\n",
        "    text = f'{label}: {score:.2f}'\n",
        "    font_scale = 1\n",
        "    text_size = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, font_scale, 3)[0]\n",
        "\n",
        "    label_start = (x_min, y_min - text_size[1] - 10)\n",
        "    label_end = (x_min + text_size[0], y_min)\n",
        "\n",
        "    cv2.rectangle(image, label_start, label_end, color, -1)\n",
        "\n",
        "    text_position = (x_min, y_min - 5)\n",
        "    cv2.putText(image, text, text_position, cv2.FONT_HERSHEY_SIMPLEX, font_scale, (255, 255, 255), 2)\n",
        "\n",
        "  output_image_path = 'output_' + image_path\n",
        "  output_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Show the image.\n",
        "  plt.figure(figsize=(12, 8))\n",
        "  plt.imshow(image)\n",
        "  plt.axis('off')\n",
        "  plt.show()\n",
        "\n",
        "  return output_image\n",
        "\n",
        "\n",
        "# Inference on video.\n",
        "def inference_video(frame, detections, color_map, out):\n",
        "    # Convert the frame to RGB for processing.\n",
        "    image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    for detection in detections:\n",
        "        box = detection['box']\n",
        "        label = detection['label']\n",
        "        score = detection['score']\n",
        "        color = color_map[label]\n",
        "\n",
        "        y_min, x_min, y_max, x_max = box\n",
        "        cv2.rectangle(image, (x_min, y_min), (x_max, y_max), color, 3)\n",
        "\n",
        "        text = f'{label}: {score:.2f}'\n",
        "        font_scale = 0.5\n",
        "        text_size = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, font_scale, 3)[0]\n",
        "\n",
        "        label_start = (x_min, y_min - text_size[1] - 10)\n",
        "        label_end = (x_min + text_size[0], y_min)\n",
        "\n",
        "        cv2.rectangle(image, label_start, label_end, color, -1)\n",
        "\n",
        "        text_position = (x_min, y_min - 5)\n",
        "        cv2.putText(image, text, text_position, cv2.FONT_HERSHEY_SIMPLEX, font_scale, (255, 255, 255), 1)\n",
        "\n",
        "    output_image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
        "    out.write(output_image)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J_EEZvtGOKEM"
      },
      "source": [
        "#### Step 8: Visualize the inference on image and video"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "33dgKKi_OP9W"
      },
      "outputs": [],
      "source": [
        "label_file = 'labels.json' # @param {type : 'string'}\n",
        "input_type = 'image' # @param ['image', 'video']\n",
        "image_path = 'test_image_2.jpg' # @param {type : 'string'}\n",
        "video_path = 'test_video.mp4' # @param {type : 'string'}\n",
        "confidence_threshold = 0.4 # @param {type : 'slider', min:0, max:1, step: 0.1}\n",
        "\n",
        "labels = load_labels(label_file)\n",
        "color_map = generate_color_map(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ax_yf-MyXe9A"
      },
      "outputs": [],
      "source": [
        "if input_type == 'image':\n",
        "    output_data, original_dims = detect(image_path)\n",
        "    detections = postprocess_output(output_data, original_dims, labels, confidence_threshold)\n",
        "    output_img = inference_image(image_path, detections, color_map)\n",
        "    output_image = 'output_' + image_path\n",
        "    cv2.imwrite(output_image, output_img)\n",
        "    print(f\"Image saved as {output_image}\")\n",
        "\n",
        "else:\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    output_video = 'output_' + video_path.replace('mp4', 'avi')\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
        "    out = cv2.VideoWriter(output_video, fourcc, 20.0, (int(cap.get(3)), int(cap.get(4))))\n",
        "\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        output_data, original_dims = detect(frame, is_video_frame=True)\n",
        "        detections = postprocess_output(output_data, original_dims, labels, confidence_threshold)\n",
        "\n",
        "        inference_video(frame, detections, color_map, out)\n",
        "\n",
        "    cap.release()\n",
        "    out.release()\n",
        "    cv2.destroyAllWindows()\n",
        "    print(f\"Output video saved as {output_video}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8P7ajg4CYWXA"
      },
      "source": [
        "#### Step 9: Download output image and video (optional)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "8Bt54ZSaYchX",
        "outputId": "f88e1aa1-403c-42f4-a298-8d41e1beedcf"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_937c37ce-6caf-45ec-9da6-2270a98d58b3\", \"output_test_image.jpg\", 277201)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_a9ab6946-59a1-42a2-bcd4-9b10828b2f80\", \"output_Leh.avi\", 74489708)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Download output image.\n",
        "files.download(output_image)\n",
        "\n",
        "# Download output video.\n",
        "files.download(output_video)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84mBrktoJZiR"
      },
      "source": [
        "#### Step 10: Download the LiteRT model\n",
        "\n",
        "Download the exported LiteRT model for on-device deployment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "BbRaAfFbIy6b",
        "outputId": "c9eeda29-530f-46ed-81dc-b7d114927205"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_c172f3d3-ea2a-45f7-8fc6-119e8b003b6d\", \"yolov10n_float16.tflite\", 5269098)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "files.download(LITE_RT_MODEL_PATH)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}